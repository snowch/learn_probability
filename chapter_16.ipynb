{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5928b3e0",
   "metadata": {},
   "source": [
    "# Chapter 16: Introduction to Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28af6cbb",
   "metadata": {},
   "source": [
    "Welcome to Chapter 16! In this chapter, we venture into the world of stochastic processes by exploring **Markov Chains**. Markov chains are a fundamental concept used to model systems that transition between different states over time, where the future state depends *only* on the current state, not on the sequence of events that preceded it. This 'memoryless' property makes them incredibly useful for modeling various real-world phenomena, from weather patterns and stock market movements to customer behavior and website navigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaaf5c6",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "* Understand the definition of a Markov chain, its components (states, transitions), and the crucial Markov property.\n",
    "* Learn how to represent Markov chains using transition matrices.\n",
    "* Simulate the behavior of a Markov chain over time using Python.\n",
    "* Calculate multi-step transition probabilities using matrix powers.\n",
    "* Gain an introductory understanding of state classification (e.g., absorbing states).\n",
    "* Learn about stationary distributions and how to find them, representing the long-run behavior of a chain.\n",
    "* Apply these concepts to practical examples using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c80627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plots for better readability\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528f223",
   "metadata": {},
   "source": [
    "## 16.1 What is a Markov Chain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a2537",
   "metadata": {},
   "source": [
    "A **Markov chain** is a mathematical model describing a sequence of possible events (or states) where the probability of transitioning to the next state depends *only* on the current state and not on the sequence of states that preceded it. This is known as the **Markov Property** (or memorylessness).\n",
    "\n",
    "Key components:\n",
    "* **States:** A finite or countably infinite set of possible conditions or positions the system can be in. Let the set of states be $S = \\{s_1, s_2, ..., s_k\\}$.\n",
    "* **Transitions:** Movements between states.\n",
    "* **Transition Probabilities:** The probability of moving from one state to another in a single time step. The probability of transitioning from state $s_i$ to state $s_j$ is denoted as $P_{ij} = P(X_{t+1} = s_j | X_t = s_i)$, where $X_t$ is the state at time $t$.\n",
    "* **Initial Distribution:** A probability distribution describing the starting state of the system at time $t=0$.\n",
    "\n",
    "**Example: Customer Subscription Model**\n",
    "\n",
    "Consider a company offering subscription plans: Free, Basic, and Premium. Customers can switch plans month-to-month, or they might churn (cancel). We can model this as a Markov chain:\n",
    "* **States:** $S = \\{\\text{'Free', 'Basic', 'Premium', 'Churned'}\\}$ \n",
    "* **Time Step:** One month.\n",
    "* **Markov Property Assumption:** The probability a customer switches to a new plan next month depends *only* on their current plan, not their entire history (e.g., whether they were Premium two months ago doesn't directly influence the next step if they are currently Basic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab7bf5",
   "metadata": {},
   "source": [
    "## 16.2 The Transition Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746abe6",
   "metadata": {},
   "source": [
    "The transition probabilities of a Markov chain with $k$ states can be conveniently organized into a $k \\times k$ matrix called the **Transition Matrix**, often denoted by $P$. \n",
    "\n",
    "$$ \n",
    "P = \\begin{pmatrix}\n",
    " P_{11} & P_{12} & \\cdots & P_{1k} \\\\\n",
    " P_{21} & P_{22} & \\cdots & P_{2k} \\\\\n",
    " \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " P_{k1} & P_{k2} & \\cdots & P_{kk}\n",
    " \\end{pmatrix}\n",
    " $$ \n",
    "\n",
    "Where $P_{ij}$ is the probability of transitioning *from* state $i$ *to* state $j$ in one step.\n",
    "\n",
    "**Properties of a Transition Matrix:**\n",
    "1.  All entries must be non-negative: $P_{ij} \\ge 0$ for all $i, j$.\n",
    "2.  The sum of probabilities in each row must equal 1: $\\sum_{j=1}^{k} P_{ij} = 1$ for all $i$. (From any state $i$, the system must transition to *some* state $j$ in the next step)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394c5cb",
   "metadata": {},
   "source": [
    "**Example: Subscription Model Transition Matrix**\n",
    "\n",
    "Let's define a plausible transition matrix for our subscription model. States are ordered: 0: Free, 1: Basic, 2: Premium, 3: Churned.\n",
    "\n",
    "| From \\\\ To | Free | Basic | Premium | Churned |\n",
    "|-----------|------|-------|---------|---------|\n",
    "| Free      | 0.60 | 0.20  | 0.10    | 0.10    |\n",
    "| Basic     | 0.10 | 0.60  | 0.20    | 0.10    |\n",
    "| Premium   | 0.05 | 0.10  | 0.70    | 0.15    |\n",
    "| Churned   | 0.00 | 0.00  | 0.00    | 1.00    |  <- Absorbing State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7383faa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix P:\n",
      "[[0.6  0.2  0.1  0.1 ]\n",
      " [0.1  0.6  0.2  0.1 ]\n",
      " [0.05 0.1  0.7  0.15]\n",
      " [0.   0.   0.   1.  ]]\n",
      "\n",
      "Row sums: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Define the states\n",
    "states = ['Free', 'Basic', 'Premium', 'Churned']\n",
    "state_map = {state: i for i, state in enumerate(states)} # Map state names to indices\n",
    "\n",
    "# Define the transition matrix P\n",
    "P = np.array([\n",
    "    [0.60, 0.20, 0.10, 0.10],  # Transitions from Free\n",
    "    [0.10, 0.60, 0.20, 0.10],  # Transitions from Basic\n",
    "    [0.05, 0.10, 0.70, 0.15],  # Transitions from Premium\n",
    "    [0.00, 0.00, 0.00, 1.00]   # Transitions from Churned (Absorbing)\n",
    "])\n",
    "\n",
    "# Verify rows sum to 1\n",
    "print(\"Transition Matrix P:\")\n",
    "print(P)\n",
    "print(\"\\nRow sums:\", P.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda5c644",
   "metadata": {},
   "source": [
    "## 16.3 Simulating Markov Chain Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe806f8f",
   "metadata": {},
   "source": [
    "We can simulate the progression of a system through states over time using the transition matrix. Given a current state, we use the corresponding row in the transition matrix as probabilities to randomly choose the next state.\n",
    "\n",
    "We can use `numpy.random.choice` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be7542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 12-month journey starting from Free:\n",
      "Free -> Basic -> Premium -> Premium -> Premium -> Premium -> Premium -> Premium -> Premium -> Premium -> Premium -> Premium -> Premium\n"
     ]
    }
   ],
   "source": [
    "def simulate_path(transition_matrix, state_names, start_state_name, num_steps):\n",
    "    \"\"\"Simulates a path through the Markov chain.\"\"\"\n",
    "    state_indices = list(range(len(state_names)))\n",
    "    current_state_index = state_names.index(start_state_name)\n",
    "    path_indices = [current_state_index]\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        # Get the transition probabilities from the current state\n",
    "        probabilities = transition_matrix[current_state_index, :]\n",
    "        \n",
    "        # Choose the next state based on these probabilities\n",
    "        next_state_index = np.random.choice(state_indices, p=probabilities)\n",
    "        path_indices.append(next_state_index)\n",
    "        \n",
    "        # Update the current state\n",
    "        current_state_index = next_state_index\n",
    "        \n",
    "        # Optional: Stop if an absorbing state (like Churned) is reached\n",
    "        if probabilities[current_state_index] == 1.0 and np.sum(probabilities) == 1.0:\n",
    "           # Check if it's an absorbing state (only loops back to itself)\n",
    "           if transition_matrix[current_state_index, current_state_index] == 1.0:\n",
    "              # Fill remaining steps if needed, or break\n",
    "              # For simplicity here, we just let it stay in the absorbing state\n",
    "              pass \n",
    "\n",
    "    # Convert indices back to state names\n",
    "    path_names = [state_names[i] for i in path_indices]\n",
    "    return path_names\n",
    "\n",
    "# Simulate a path for 12 months starting from 'Free'\n",
    "start_state = 'Free'\n",
    "steps = 12\n",
    "simulated_journey = simulate_path(P, states, start_state, steps)\n",
    "\n",
    "print(f\"Simulated {steps}-month journey starting from {start_state}:\")\n",
    "print(\" -> \".join(simulated_journey))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a93174",
   "metadata": {},
   "source": [
    "Run the simulation cell multiple times to see different possible paths a customer might take."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bacd7",
   "metadata": {},
   "source": [
    "## 16.4 n-Step Transition Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e88801",
   "metadata": {},
   "source": [
    "The transition matrix $P$ gives the probabilities of moving between states in *one* step. What if we want to know the probability of transitioning from state $i$ to state $j$ in *n* steps?\n",
    "\n",
    "This is given by the $(i, j)$-th entry of the matrix power $P^n$. \n",
    "\n",
    "$P^{(n)}_{ij} = P(X_{t+n} = s_j | X_t = s_i) = (P^n)_{ij}$\n",
    "\n",
    "We can calculate matrix powers using `numpy.linalg.matrix_power`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72eb3952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix after 3 steps (P^3):\n",
      "[[0.264 0.244 0.208 0.284]\n",
      " [0.132 0.293 0.282 0.294]\n",
      " [0.085 0.15  0.396 0.369]\n",
      " [0.    0.    0.    1.   ]]\n",
      "\n",
      "Probability(State=Premium at month 3 | State=Free at month 0): 0.207\n",
      "Probability(State=Churned at month 6 | State=Basic at month 0): 0.521\n"
     ]
    }
   ],
   "source": [
    "# Calculate the transition matrix after 3 steps (months)\n",
    "n_steps = 3\n",
    "P_n = np.linalg.matrix_power(P, n_steps)\n",
    "\n",
    "print(f\"Transition Matrix after {n_steps} steps (P^{n_steps}):\")\n",
    "print(np.round(P_n, 3)) # Round for readability\n",
    "\n",
    "# Example: Probability of being in 'Premium' after 3 months, starting from 'Free'\n",
    "start_idx = state_map['Free']\n",
    "end_idx = state_map['Premium']\n",
    "prob_free_to_premium_3_steps = P_n[start_idx, end_idx]\n",
    "\n",
    "print(f\"\\nProbability(State=Premium at month 3 | State=Free at month 0): {prob_free_to_premium_3_steps:.3f}\")\n",
    "\n",
    "# Example: Probability of being 'Churned' after 6 months, starting from 'Basic'\n",
    "n_steps_long = 6\n",
    "P_n_long = np.linalg.matrix_power(P, n_steps_long)\n",
    "start_idx_basic = state_map['Basic']\n",
    "end_idx_churned = state_map['Churned']\n",
    "prob_basic_to_churned_6_steps = P_n_long[start_idx_basic, end_idx_churned]\n",
    "\n",
    "print(f\"Probability(State=Churned at month 6 | State=Basic at month 0): {prob_basic_to_churned_6_steps:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b150b5a",
   "metadata": {},
   "source": [
    "## 16.5 Classification of States (Brief Introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c9b05",
   "metadata": {},
   "source": [
    "States in a Markov chain can be classified based on their long-term behavior:\n",
    "\n",
    "* **Accessible:** State $j$ is accessible from state $i$ if there is a non-zero probability of eventually reaching $j$ starting from $i$ (i.e., $P^{(n)}_{ij} > 0$ for some $n \\ge 0$).\n",
    "* **Communicating:** States $i$ and $j$ communicate if they are accessible from each other.\n",
    "* **Irreducible Chain:** A Markov chain is irreducible if all states communicate with each other (it's possible to get from any state to any other state).\n",
    "* **Recurrent State:** If starting from state $i$, the probability of eventually returning to state $i$ is 1. \n",
    "* **Transient State:** If starting from state $i$, there is a non-zero probability of *never* returning to state $i$. \n",
    "* **Absorbing State:** A state $i$ is absorbing if once entered, it cannot be left ($P_{ii} = 1$). In our example, 'Churned' is an absorbing state.\n",
    "\n",
    "In our subscription model:\n",
    "* 'Churned' is an absorbing state.\n",
    "* 'Free', 'Basic', and 'Premium' are likely transient states because from any of them, there is a path to 'Churned', and once in 'Churned', you cannot return.\n",
    "* The chain is *not* irreducible because you cannot leave the 'Churned' state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e26bec",
   "metadata": {},
   "source": [
    "## 16.6 Stationary Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe282348",
   "metadata": {},
   "source": [
    "For certain types of Markov chains (specifically, irreducible and aperiodic ones), the distribution of probabilities across states converges to a unique **stationary distribution** (or steady-state distribution), regardless of the initial state. Let $\\pi = [\\pi_1, \\pi_2, ..., \\pi_k]$ be the row vector representing this distribution, where $\\pi_j$ is the long-run probability of being in state $j$.\n",
    "\n",
    "The stationary distribution $\\pi$ satisfies the equation:\n",
    "\n",
    "$$ \\pi P = \\pi $$ \n",
    "\n",
    "subject to the constraint that $\\sum_{j=1}^{k} \\pi_j = 1$.\n",
    "\n",
    "This means that if the distribution of states is $\\pi$, it will remain $\\pi$ after one more step. $\\pi$ is the left eigenvector of the transition matrix $P$ corresponding to the eigenvalue $\\lambda = 1$.\n",
    "\n",
    "**Important Note:** Our subscription model has an absorbing state. In such cases, the long-run probability will eventually concentrate entirely in the absorbing state(s). For any starting state other than 'Churned', the probability of being in 'Churned' approaches 1 as $n \\to \\infty$. The concept of a unique stationary distribution across *all* states applies more directly to chains where you can always move between states (irreducible chains)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2b96f",
   "metadata": {},
   "source": [
    "**Example: Finding Stationary Distribution for a Weather Model**\n",
    "\n",
    "Let's consider a simpler, irreducible weather model (Sunny, Cloudy, Rainy) to illustrate finding a stationary distribution.\n",
    "\n",
    "Weather States: `['Sunny', 'Cloudy', 'Rainy']`\n",
    "Weather Matrix `W`:\n",
    "```\n",
    "   Sunny Cloudy Rainy\n",
    "Sunny  [0.7,  0.2,   0.1]\n",
    "Cloudy [0.3,  0.5,   0.2]\n",
    "Rainy  [0.2,  0.4,   0.4]\n",
    "```\n",
    "We need to find $\\pi = [\\pi_S, \\pi_C, \\pi_R]$ such that $\\pi W = \\pi$ and $\\pi_S + \\pi_C + \\pi_R = 1$. This is equivalent to finding the left eigenvector for eigenvalue 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4352a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary Distribution (Long-run probabilities):\n",
      "  Sunny: 0.4681\n",
      "  Cloudy: 0.3404\n",
      "  Rainy: 0.1915\n",
      "\n",
      "Verification (pi * W): [0.46808511 0.34042553 0.19148936]\n"
     ]
    }
   ],
   "source": [
    "# Weather example\n",
    "W_states = ['Sunny', 'Cloudy', 'Rainy']\n",
    "W = np.array([\n",
    "    [0.7, 0.2, 0.1],\n",
    "    [0.3, 0.5, 0.2],\n",
    "    [0.2, 0.4, 0.4]\n",
    "])\n",
    "\n",
    "# Find eigenvalues and eigenvectors\n",
    "# We need the *left* eigenvector (v P = lambda v), numpy finds *right* (P u = lambda u).\n",
    "# The left eigenvector of P for eigenvalue lambda is the right eigenvector of P.T for eigenvalue lambda.\n",
    "eigenvalues, eigenvectors = np.linalg.eig(W.T)\n",
    "\n",
    "# Find the eigenvector corresponding to eigenvalue 1\n",
    "# Due to floating point precision, check for eigenvalues close to 1\n",
    "idx = np.isclose(eigenvalues, 1)\n",
    "\n",
    "if not np.any(idx):\n",
    "    print(\"No eigenvalue close to 1 found. Check matrix.\")\n",
    "else:\n",
    "    # Get the eigenvector corresponding to eigenvalue 1\n",
    "    # Ensure we select only one eigenvector if multiple eigenvalues are close to 1\n",
    "    # and take the real part as the eigenvector should be real for a stochastic matrix\n",
    "    stationary_vector_raw = eigenvectors[:, np.where(idx)[0][0]].flatten().real\n",
    "    \n",
    "    # Normalize the eigenvector so its components sum to 1\n",
    "    stationary_distribution = stationary_vector_raw / np.sum(stationary_vector_raw)\n",
    "\n",
    "    print(\"Stationary Distribution (Long-run probabilities):\")\n",
    "    for state, prob in zip(W_states, stationary_distribution):\n",
    "        print(f\"  {state}: {prob:.4f}\")\n",
    "\n",
    "    # Verification: pi * W should be equal to pi\n",
    "    print(\"\\nVerification (pi * W):\", np.dot(stationary_distribution, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393793e",
   "metadata": {},
   "source": [
    "This stationary distribution tells us that, in the long run, regardless of whether today is Sunny, Cloudy, or Rainy, the probability of a future day being Sunny is about 44.7%, Cloudy is about 36.8%, and Rainy is about 18.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5759209",
   "metadata": {},
   "source": [
    "## 16.7 Hands-on: Analyzing the Subscription Model Long-Term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50eb89a",
   "metadata": {},
   "source": [
    "Let's use our simulation and n-step transition probabilities to see what happens to subscribers in the long run in our original model with the 'Churned' state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c066b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of states after 24 months starting from 'Basic' (based on 5000 simulations):\n",
      "  Free: 0.0088\n",
      "  Basic: 0.0128\n",
      "  Premium: 0.0210\n",
      "  Churned: 0.9574\n",
      "\n",
      "Theoretical probabilities after 24 months starting from 'Basic':\n",
      "  Free: 0.0090\n",
      "  Basic: 0.0142\n",
      "  Premium: 0.0212\n",
      "  Churned: 0.9556\n"
     ]
    }
   ],
   "source": [
    "# Simulate many paths to see the distribution of final states\n",
    "num_simulations = 5000\n",
    "simulation_length = 24 # Simulate for 2 years\n",
    "final_states = []\n",
    "\n",
    "initial_state = 'Basic' # Example starting state\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    path = simulate_path(P, states, initial_state, simulation_length)\n",
    "    final_states.append(path[-1]) # Get the state after 'simulation_length' months\n",
    "\n",
    "# Calculate the proportion of simulations ending in each state\n",
    "from collections import Counter # Efficient way to count\n",
    "final_state_counts = Counter(final_states)\n",
    "# Ensure all states are present in the counts, even if 0\n",
    "for state in states:\n",
    "    if state not in final_state_counts:\n",
    "        final_state_counts[state] = 0\n",
    "\n",
    "final_state_proportions = {state: final_state_counts[state] / num_simulations for state in states}\n",
    "\n",
    "print(f\"Distribution of states after {simulation_length} months starting from '{initial_state}' (based on {num_simulations} simulations):\")\n",
    "for state in states: # Print in consistent order\n",
    "    print(f\"  {state}: {final_state_proportions[state]:.4f}\")\n",
    "\n",
    "# Compare with n-step transition probability calculation\n",
    "P_long_term = np.linalg.matrix_power(P, simulation_length)\n",
    "start_idx = state_map[initial_state]\n",
    "theoretical_probs = P_long_term[start_idx, :]\n",
    "\n",
    "print(f\"\\nTheoretical probabilities after {simulation_length} months starting from '{initial_state}':\")\n",
    "for i, state in enumerate(states):\n",
    "    print(f\"  {state}: {theoretical_probs[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62017ca6",
   "metadata": {},
   "source": [
    "Notice how the simulation results closely match the theoretical probabilities calculated using the matrix power $P^n$. Also, observe that as the number of steps (`simulation_length`) increases, the probability mass shifts significantly towards the 'Churned' state, as expected for a model with an absorbing state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864833e6",
   "metadata": {},
   "source": [
    "## 16.8 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6299d3",
   "metadata": {},
   "source": [
    "In this chapter, we introduced Markov chains, a powerful tool for modeling systems that transition between states based only on their current state. \n",
    "\n",
    "We learned:\n",
    "* The definition of states, transitions, and the Markov property.\n",
    "* How to use transition matrices ($P$) to represent one-step probabilities.\n",
    "* To simulate Markov chain paths using Python and `np.random.choice`.\n",
    "* That matrix powers ($P^n$) give n-step transition probabilities.\n",
    "* The basic classification of states, including absorbing states.\n",
    "* The concept of a stationary distribution ($\\pi P = \\pi$) for irreducible, aperiodic chains, representing long-run behavior, and how to find it using eigenvectors.\n",
    "\n",
    "Markov chains form the basis for many more advanced models and algorithms in fields like reinforcement learning, finance, genetics, and operations research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd634e8",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4b847",
   "metadata": {},
   "source": [
    "1.  **Simple Weather Model:** Consider the weather model (Sunny, Cloudy, Rainy) with transition matrix `W`. If it's Sunny today, what is the probability it will be Rainy the day after tomorrow (in 2 steps)? Calculate this using matrix multiplication.\n",
    "2.  **Gambler's Ruin (Simulation):** A gambler starts with \\$3. They bet \\$1 on a fair coin flip (50% chance win, 50% chance lose). They stop if they reach \\$0 (ruin) or \\$5 (win). \n",
    "    a. Define the states (amount of money: 0, 1, 2, 3, 4, 5).\n",
    "    b. Define the transition matrix. Note the absorbing states 0 and 5.\n",
    "    c. Simulate 10000 games starting from \\$3. What proportion end in ruin (\\$0) and what proportion end in winning (\\$5)?\n",
    "3.  **Stationary Distribution Verification:** For the weather model, manually verify that the calculated stationary distribution $\\pi$ satisfies $\\pi W = \\pi$. \n",
    "4.  **Modify Subscription Model:** Change the 'Churned' state in the subscription model `P` so that there's a small probability (e.g., 0.05) of a churned customer re-subscribing to the 'Free' plan each month (adjust the $P_{33}$ probability accordingly so the row still sums to 1). Is the chain still absorbing? Try to find the new stationary distribution using the eigenvector method. What does it represent now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a70aaa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Exercise 1) Probability Sunny -> Rainy in 2 steps: 0.1500\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1 Code/Calculation Space\n",
    "W_states = ['Sunny', 'Cloudy', 'Rainy']\n",
    "W = np.array([\n",
    "    [0.7, 0.2, 0.1],\n",
    "    [0.3, 0.5, 0.2],\n",
    "    [0.2, 0.4, 0.4]\n",
    "])\n",
    "\n",
    "# Calculate W^2\n",
    "W_2 = np.linalg.matrix_power(W, 2)\n",
    "\n",
    "# Probability Sunny -> Rainy in 2 steps\n",
    "sunny_idx = W_states.index('Sunny')\n",
    "rainy_idx = W_states.index('Rainy')\n",
    "prob_sunny_to_rainy_2_steps = W_2[sunny_idx, rainy_idx]\n",
    "print(f\"(Exercise 1) Probability Sunny -> Rainy in 2 steps: {prob_sunny_to_rainy_2_steps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb1f05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Exercise 2) Gambler's Ruin Simulation (10000 games starting at $3):\n",
      "  Proportion ending in Ruin ($0): 0.4024\n",
      "  Proportion ending in Win ($5): 0.5976\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2 Code/Calculation Space\n",
    "# Gambler's Ruin\n",
    "gambler_states = [0, 1, 2, 3, 4, 5] # Amount of money\n",
    "P_gambler = np.array([\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0], # From 0 (Ruin)\n",
    "    [0.5, 0.0, 0.5, 0.0, 0.0, 0.0], # From 1\n",
    "    [0.0, 0.5, 0.0, 0.5, 0.0, 0.0], # From 2\n",
    "    [0.0, 0.0, 0.5, 0.0, 0.5, 0.0], # From 3\n",
    "    [0.0, 0.0, 0.0, 0.5, 0.0, 0.5], # From 4\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  # From 5 (Win)\n",
    "])\n",
    "\n",
    "def simulate_gambler(transition_matrix, states, start_state_val, max_steps=200): # Increased max_steps slightly\n",
    "    \"\"\"Simulates one game until an absorbing state is reached.\"\"\"\n",
    "    state_indices = list(range(len(states)))\n",
    "    current_state_index = states.index(start_state_val)\n",
    "    #path_indices = [current_state_index] # Path not needed for final state only\n",
    "\n",
    "    steps = 0\n",
    "    while steps < max_steps:\n",
    "        current_state_val = states[current_state_index]\n",
    "        # Check if in absorbing state\n",
    "        if current_state_val == 0 or current_state_val == 5:\n",
    "            return current_state_val # Return final state\n",
    "            \n",
    "        probabilities = transition_matrix[current_state_index, :]\n",
    "        next_state_index = np.random.choice(state_indices, p=probabilities)\n",
    "        #path_indices.append(next_state_index)\n",
    "        current_state_index = next_state_index\n",
    "        steps += 1\n",
    "        \n",
    "    # If max_steps reached without hitting absorbing state (unlikely here but good practice)\n",
    "    return states[current_state_index] \n",
    "\n",
    "num_games = 10000 # Increased simulations for better accuracy\n",
    "start_money = 3\n",
    "end_results = []\n",
    "for _ in range(num_games):\n",
    "    end_results.append(simulate_gambler(P_gambler, gambler_states, start_money))\n",
    "\n",
    "from collections import Counter\n",
    "end_counts = Counter(end_results)\n",
    "\n",
    "ruin_count = end_counts.get(0, 0) # Use .get for safety\n",
    "win_count = end_counts.get(5, 0)\n",
    "\n",
    "print(f\"\\n(Exercise 2) Gambler's Ruin Simulation ({num_games} games starting at ${start_money}):\")\n",
    "print(f\"  Proportion ending in Ruin ($0): {ruin_count / num_games:.4f}\") # Should be 0.4\n",
    "print(f\"  Proportion ending in Win ($5): {win_count / num_games:.4f}\")  # Should be 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e9045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Exercise 3) Stationary Distribution Verification:\n",
      "  Calculated pi: [0.46808511 0.34042553 0.19148936]\n",
      "  Result pi * W: [0.46808511 0.34042553 0.19148936]\n",
      "  Are they close? True\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3 Code/Calculation Space\n",
    "# Verification: pi * W = pi\n",
    "\n",
    "# From previous calculation (ensure these are accurate)\n",
    "# Recalculate just in case\n",
    "eigenvalues, eigenvectors = np.linalg.eig(W.T)\n",
    "idx = np.isclose(eigenvalues, 1)\n",
    "stationary_vector_raw = eigenvectors[:, np.where(idx)[0][0]].flatten().real\n",
    "pi_weather = stationary_vector_raw / np.sum(stationary_vector_raw)\n",
    "\n",
    "result_vector = np.dot(pi_weather, W)\n",
    "\n",
    "print(\"\\n(Exercise 3) Stationary Distribution Verification:\")\n",
    "print(f\"  Calculated pi: {pi_weather}\")\n",
    "print(f\"  Result pi * W: {result_vector}\")\n",
    "# Use np.allclose for robust floating point comparison\n",
    "print(f\"  Are they close? {np.allclose(pi_weather, result_vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38dd55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Exercise 4) Modified Transition Matrix:\n",
      "[[0.6  0.2  0.1  0.1 ]\n",
      " [0.1  0.6  0.2  0.1 ]\n",
      " [0.05 0.1  0.7  0.15]\n",
      " [0.05 0.   0.   0.95]]\n",
      "\n",
      "Is 'Churned' still absorbing? False\n",
      "The chain is no longer absorbing, as state 'Churned' can transition to 'Free'.\n",
      "The chain should now be irreducible if all other states can eventually reach Churned and Churned can reach Free.\n",
      "\n",
      "Stationary Distribution for Modified Matrix:\n",
      "  Free: 0.1205\n",
      "  Basic: 0.0843\n",
      "  Premium: 0.0964\n",
      "  Churned: 0.6988\n",
      "\n",
      "This represents the long-run proportion of time the system spends in each state.\n",
      "Even though customers churn, the small chance of returning means there's a non-zero steady state for all plans.\n",
      "\n",
      "Verification (pi_mod * P_mod): [0.12048193 0.08433735 0.09638554 0.69879518]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4 Code/Calculation Space\n",
    "\n",
    "# Reload original P and states just in case they were modified\n",
    "states = ['Free', 'Basic', 'Premium', 'Churned']\n",
    "state_map = {state: i for i, state in enumerate(states)}\n",
    "P = np.array([\n",
    "    [0.60, 0.20, 0.10, 0.10],  # Transitions from Free\n",
    "    [0.10, 0.60, 0.20, 0.10],  # Transitions from Basic\n",
    "    [0.05, 0.10, 0.70, 0.15],  # Transitions from Premium\n",
    "    [0.00, 0.00, 0.00, 1.00]   # Transitions from Churned (Absorbing)\n",
    "])\n",
    "\n",
    "P_modified = P.copy() # Start with original subscription matrix\n",
    "\n",
    "# Modify the 'Churned' row (index 3)\n",
    "prob_churn_to_free = 0.05\n",
    "P_modified[3, state_map['Free']] = prob_churn_to_free\n",
    "P_modified[3, state_map['Churned']] = 1.0 - prob_churn_to_free # Adjust P_33\n",
    "\n",
    "print(\"\\n(Exercise 4) Modified Transition Matrix:\")\n",
    "print(P_modified)\n",
    "print(\"\\nIs 'Churned' still absorbing?\", P_modified[3, 3] == 1.0) # Should be False\n",
    "print(\"The chain is no longer absorbing, as state 'Churned' can transition to 'Free'.\")\n",
    "print(\"The chain should now be irreducible if all other states can eventually reach Churned and Churned can reach Free.\")\n",
    "\n",
    "# Try finding the stationary distribution for the modified matrix\n",
    "eigenvalues_mod, eigenvectors_mod = np.linalg.eig(P_modified.T)\n",
    "idx_mod = np.isclose(eigenvalues_mod, 1)\n",
    "\n",
    "if not np.any(idx_mod):\n",
    "    print(\"\\nNo eigenvalue close to 1 found for modified matrix.\")\n",
    "else:\n",
    "    stationary_vector_raw_mod = eigenvectors_mod[:, np.where(idx_mod)[0][0]].flatten().real\n",
    "    stationary_distribution_mod = stationary_vector_raw_mod / np.sum(stationary_vector_raw_mod)\n",
    "    \n",
    "    print(\"\\nStationary Distribution for Modified Matrix:\")\n",
    "    for state, prob in zip(states, stationary_distribution_mod):\n",
    "        print(f\"  {state}: {prob:.4f}\")\n",
    "    \n",
    "    print(\"\\nThis represents the long-run proportion of time the system spends in each state.\")\n",
    "    print(\"Even though customers churn, the small chance of returning means there's a non-zero steady state for all plans.\")\n",
    "    # Verification\n",
    "    print(\"\\nVerification (pi_mod * P_mod):\", np.dot(stationary_distribution_mod, P_modified))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
